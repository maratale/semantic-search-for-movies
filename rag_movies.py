#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RAG over hybrid movie search ‚Äî –±–µ–∑ –±–æ–∫–æ–≤–æ–≥–æ –º–µ–Ω—é, —Å –∫–∞—Ä—Ç–æ—á–∫–∞–º–∏ –ø–æ—Å—Ç–µ—Ä–æ–≤ —Å—Ä–∞–∑—É –≤ –≤—ã–¥–∞—á–µ.

- –ë–µ—Ä—ë—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ semantic_search_movies.run_query (–≤–∞—à –≥–∏–±—Ä–∏–¥–Ω—ã–π –∏–Ω–¥–µ–∫—Å).
- –°–æ–±–∏—Ä–∞–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (title, year, genres, cast, plot, url).
- –í—ã–∑—ã–≤–∞–µ—Ç LLM (GPT-4o/*) –¥–ª—è —Å–≤—è–∑–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.
- –í –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ: –ø–æ–ª—è –≤–≤–æ–¥–∞ –Ω–∞–≤–µ—Ä—Ö—É, –∑–∞—Ç–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ñ–∏–ª—å–º–æ–≤ —Å –ø–æ—Å—Ç–µ—Ä–∞–º–∏.

–ó–∞–ø—É—Å–∫:
  python -m streamlit run rag_movies.py -- app --index ./index_hybrid

–¢—Ä–µ–±—É–µ—Ç—Å—è:
  pip install streamlit requests
  (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) pip install beautifulsoup4  # —á—Ç–æ–±—ã –≤—ã—Ç—è–≥–∏–≤–∞—Ç—å og:image —Å page_url

–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
  OPENAI_API_KEY ‚Äî –∫–ª—é—á OpenAI (–≤ Streamlit Cloud –ø–æ–ª–æ–∂–∏—Ç–µ –≤ Secrets).
"""

import os, sys, argparse
from typing import Optional
import pandas as pd

# ---------- API key & client ----------
def _get_api_key() -> Optional[str]:
    key = os.getenv("OPENAI_API_KEY")
    if not key:
        try:
            import streamlit as st
            key = st.secrets.get("OPENAI_API_KEY", None) if hasattr(st, "secrets") else None
        except Exception:
            pass
    return key

def _make_client():
    key = _get_api_key()
    if not key:
        raise RuntimeError("OPENAI_API_KEY is not set (env or Streamlit secrets).")
    from openai import OpenAI
    return OpenAI(api_key=key)

# ---------- –ò–º–ø–æ—Ä—Ç —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ ----------
try:
    import semantic_search_movies as retr  # –æ–∂–∏–¥–∞–µ—Ç—Å—è run_query(out_dir, query, k)
except Exception:
    retr = None

# ---------- –£—Ç–∏–ª–∏—Ç—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ----------
def _shorten(s: str, n: int = 550) -> str:
    s = (s or "").strip()
    return s if len(s) <= n else s[:n].rsplit(" ", 1)[0] + "‚Ä¶"

def _as_year(x) -> str:
    s = str(x or "").strip()
    for ch in "[](){}":
        s = s.replace(ch, "")
    y = "".join(c for c in s if c.isdigit())
    return y[:4] if len(y) >= 4 else s

def _build_context(df: pd.DataFrame, k: int) -> str:
    blocks = []
    for _, row in df.head(k).iterrows():
        title = str(row.get("movie_title", "")).strip()
        year  = _as_year(row.get("release_date", ""))
        cats  = str(row.get("categories", "")).strip()
        actors = str(row.get("actors", "")).strip()
        directors = str(row.get("directors", "")).strip()
        desc = _shorten(str(row.get("description", "")))
        url  = str(row.get("page_url", "")).strip()

        b = []
        b.append(f"Title: {title}" + (f" ({year})" if year else ""))
        if cats:      b.append(f"Genres: {cats}")
        if directors: b.append(f"Directors: {directors}")
        if actors:    b.append(f"Cast: {actors}")
        if desc:      b.append(f"Plot: {desc}")
        if url.startswith("http"): b.append(f"URL: {url}")
        blocks.append("\n".join(b))
    return "\n\n---\n\n".join(blocks)

SYS_PROMPT = (
    "–¢—ã ‚Äî –∫–∏–Ω–æ–∫—Ä–∏—Ç–∏–∫ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞. –û—Ç–≤–µ—á–∞–π –ø–æ-—Ä—É—Å—Å–∫–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ.\n"
    "–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Å–ø–∏—Å–æ–∫ —Ñ–∏–ª—å–º–æ–≤), –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç–æ–≤.\n"
    "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:\n"
    "1) –ö–æ—Ä–æ—Ç–∫–æ –æ—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)\n"
    "2) –ü–æ–¥–±–æ—Ä–∫–∞ 5‚Äì10 —Ñ–∏–ª—å–º–æ–≤ —Å –ø—Ä–∏—á–∏–Ω–∞–º–∏ (–ø–æ 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ —Ñ–∏–ª—å–º)\n"
    "3) –ï—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã/–ø–æ–¥–±–æ—Ä–∫–∏\n"
    "–í—Å–µ–≥–¥–∞ —É–∫–∞–∑—ã–≤–∞–π –≥–æ–¥, –∂–∞–Ω—Ä—ã, –º–æ–∂–Ω–æ –∞–∫—Ç—ë—Ä–æ–≤/—Ä–µ–∂–∏—Å—Å—ë—Ä–æ–≤; –¥–æ–±–∞–≤–ª—è–π —Å—Å—ã–ª–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å.\n"
)

USER_PROMPT_TMPL = """–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
{query}

–ö–æ–Ω—Ç–µ–∫—Å—Ç (–∫–∞–Ω–¥–∏–¥–∞—Ç—ã —Ñ–∏–ª—å–º–æ–≤):
{context}

–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤—ã–±—Ä–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ–∏–ª—å–º—ã, –æ–±—ä—è—Å–Ω–∏—Ç—å –≤—ã–±–æ—Ä –∏ —Å–≤—è–∑–∞—Ç—å –∏—Ö —Å –∑–∞–ø—Ä–æ—Å–æ–º.
–ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –ø–æ–∫—Ä—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ —ç—Ç–æ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –±–ª–∏–∂–∞–π—à–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
"""

# ---------- –í—ã–∑–æ–≤ LLM ----------
def call_openai(prompt: str, system: str = SYS_PROMPT, model: str = "gpt-4o-mini") -> str:
    # –æ—Å–Ω–æ–≤–Ω–æ–π –ø—É—Ç—å ‚Äî –Ω–æ–≤—ã–π SDK
    try:
        client = _make_client()
        r = client.chat.completions.create(
            model=model,
            messages=[{"role": "system", "content": system},
                      {"role": "user",   "content": prompt}],
            temperature=0.4,
            max_tokens=900,
        )
        return r.choices[0].message.content.strip()
    except Exception as e_new:
        # —Ñ–æ–ª–±—ç–∫ –Ω–∞ —Å—Ç–∞—Ä—ã–π SDK, –µ—Å–ª–∏ –≤–¥—Ä—É–≥
        try:
            import openai
            key = _get_api_key()
            if not key:
                return f"[LLM disabled] {e_new}\n\n" + prompt
            openai.api_key = key
            r = openai.ChatCompletion.create(
                model=model,
                messages=[{"role": "system", "content": system},
                          {"role": "user",   "content": prompt}],
                temperature=0.4,
                max_tokens=900,
            )
            return r["choices"][0]["message"]["content"].strip()
        except Exception as e_old:
            return f"[OpenAI error] {e_old}\n\n" + prompt

# ---------- –†–µ—Ç—Ä–∏–≤–µ—Ä-–æ–±—ë—Ä—Ç–∫–∞ ----------
def retrieve(index_dir: str, query: str, k: int = 12) -> pd.DataFrame:
    if retr and hasattr(retr, "run_query"):
        return retr.run_query(index_dir, query, k=k)
    # fallback: –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ–π –º–∞—Ç—á –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ (–µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –Ω–µ —Å–æ–±—Ä–∞–Ω)
    meta_path = os.path.join(index_dir, "meta.parquet")
    if not os.path.exists(meta_path):
        raise FileNotFoundError(f"No meta.parquet in {index_dir}; build your index first.")
    df = pd.read_parquet(meta_path)
    q = query.lower()
    mask = (
        df.get("movie_title", pd.Series(dtype=str)).str.lower().str.contains(q, na=False) |
        df.get("directors",   pd.Series(dtype=str)).str.lower().str.contains(q, na=False) |
        df.get("actors",      pd.Series(dtype=str)).str.lower().str.contains(q, na=False) |
        df.get("description", pd.Series(dtype=str)).str.lower().str.contains(q, na=False)
    )
    out = df[mask].copy()
    if out.empty:
        out = df.sample(min(k, len(df)), random_state=42).copy()
    out.insert(0, "final_score", 0.0)
    return out.head(k)

# ---------- RAG ----------
def rag_answer(index_dir: str, query: str, k: int = 10,
               llm_backend: str = "openai", llm_model: str = "gpt-4o-mini") -> tuple[str, pd.DataFrame]:
    hits = retrieve(index_dir, query, k=max(k, 12))
    ctx = _build_context(hits, k=max(k, 12))
    prompt = USER_PROMPT_TMPL.format(query=query, context=ctx)
    if llm_backend == "openai":
        answer = call_openai(prompt, model=llm_model)
    else:
        answer = "[No LLM backend configured]\n\n" + prompt
    return answer, hits

# ---------- –ü–æ—Å—Ç–µ—Ä—ã: —É—Ç–∏–ª–∏—Ç—ã ----------
import requests
from urllib.parse import urlparse
try:
    from bs4 import BeautifulSoup
    HAS_BS4 = True
except Exception:
    HAS_BS4 = False

def _is_http_url(s: str) -> bool:
    try:
        u = urlparse(str(s).strip())
        return u.scheme in ("http", "https") and bool(u.netloc)
    except Exception:
        return False

def _clean_url(s: str) -> str:
    return str(s or "").strip()

def _safe_get(url: str, timeout: float = 5.0) -> Optional[requests.Response]:
    try:
        headers = {"User-Agent": "Mozilla/5.0 (compatible; RAGMoviesBot/1.0)"}
        r = requests.get(url, headers=headers, timeout=timeout)
        if r.status_code == 200 and r.content:
            return r
    except Exception:
        pass
    return None

def _extract_og_image(html: str) -> Optional[str]:
    if not HAS_BS4:
        return None
    try:
        soup = BeautifulSoup(html, "html.parser")
        for prop in ("og:image", "twitter:image", "og:image:url"):
            tag = soup.find("meta", attrs={"property": prop}) or soup.find("meta", attrs={"name": prop})
            if tag:
                content = tag.get("content") or tag.get("value")
                if content and _is_http_url(content):
                    return content
    except Exception:
        pass
    return None

# ---------- CLI ----------
def cmd_answer(args):
    ans, hits = rag_answer(args.index, args.q, k=args.k, llm_backend=args.backend, llm_model=args.model)
    print("\n=== ANSWER ===\n")
    print(ans)
    print("\n=== SOURCES ===\n")
    cols = [c for c in ["movie_title","release_date","categories","actors","directors","page_url"] if c in hits.columns]
    print(hits.head(args.k)[cols].to_string(index=False, max_colwidth=120))

# ---------- Streamlit UI (–±–µ–∑ –±–æ–∫–æ–≤–æ–≥–æ –º–µ–Ω—é) ----------
def cmd_app(args):
    import streamlit as st
    st.set_page_config(page_title="RAG over Movies", layout="wide")
    st.title("üß† RAG –ø–æ —Ñ–∏–ª—å–º–∞–º (–≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ + LLM)")

    # –ü–∞–Ω–µ–ª—å –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Å–≤–µ—Ä—Ö—É (–ù–ï sidebar)
    with st.container():
        col1, col2, col3, col4, col5 = st.columns([2, 1, 1, 1, 1])
        with col1:
            index_dir = st.text_input("–ü–∞–ø–∫–∞ –∏–Ω–¥–µ–∫—Å–∞", args.index or "./index_hybrid")
        with col2:
            k = st.number_input("Top-K", min_value=5, max_value=20, value=10, step=1)
        with col3:
            llm_model = st.selectbox("LLM-–º–æ–¥–µ–ª—å", ["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini", "gpt-4.1"], index=0)
        with col4:
            img_w = st.number_input("–®–∏—Ä–∏–Ω–∞ –ø–æ—Å—Ç–µ—Ä–∞ (px)", min_value=120, max_value=360, value=200, step=10)
        with col5:
            allow_fetch = st.checkbox("og:image –∏–∑ page_url", value=False, help="–ï—Å–ª–∏ –Ω–µ—Ç poster_url, –ø—Ä–æ–±—É–µ–º –º–µ—Ç–∞-—Ç–µ–≥–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã")

    show_plot = st.checkbox("–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ", value=True)

    has_key = bool(_get_api_key())
    if not has_key:
        st.warning("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á–µ–Ω–∞.")

    q = st.text_input("–í–∞—à –∑–∞–ø—Ä–æ—Å", "—Ä–æ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –∫–æ–º–µ–¥–∏—è –≤ –±–æ–ª—å—à–æ–º –≥–æ—Ä–æ–¥–µ")
    go = st.button("–ù–∞–π—Ç–∏ –∏ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç", disabled=not has_key)

    if go and q.strip():
        with st.spinner("–ò—â–µ–º –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç‚Ä¶"):
            ans, hits = rag_answer(index_dir, q, k=int(k), llm_backend="openai", llm_model=llm_model)

        # –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
        st.markdown("## –û—Ç–≤–µ—Ç")
        st.write(ans)

        # –ö–∞—Ä—Ç–æ—á–∫–∏ —Ñ–∏–ª—å–º–æ–≤ —Å—Ä–∞–∑—É –ø–æ–¥ –æ—Ç–≤–µ—Ç–æ–º
        st.markdown("## –ü–æ–¥–±–æ—Ä–∫–∞ —Ñ–∏–ª—å–º–æ–≤")
        # –ª–æ–∫–∞–ª—å–Ω—ã–π –∫—ç—à –≤–Ω—É—Ç—Ä–∏ —Å–µ—Å—Å–∏–∏
        @st.cache_data(show_spinner=False)
        def cached_poster_from_page(url: str) -> Optional[str]:
            resp = _safe_get(url)
            if resp is None:
                return None
            og = _extract_og_image(resp.text)
            return og if (og and _is_http_url(og)) else None

        for _, row in hits.iterrows():
            title = str(row.get("movie_title","(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)")).strip() or "(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)"
            meta_line = " | ".join(filter(None, [
                str(row.get("categories","")).strip(),
                str(row.get("release_date","")).strip(),
            ]))

            # –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ—Å—Ç–µ—Ä
            poster = None
            for key in ("poster_url","image_url","poster","thumbnail"):
                val = _clean_url(row.get(key, ""))
                if _is_http_url(val):
                    poster = val
                    break
            if poster is None and allow_fetch:
                page_url = _clean_url(row.get("page_url",""))
                if _is_http_url(page_url):
                    poster = cached_poster_from_page(page_url)

            box = st.container()
            col_img, col_txt = box.columns([1,3], vertical_alignment="center")

            with col_img:
                if poster:
                    st.image(poster, width=int(img_w))
                else:
                    st.markdown(
                        f"<div style='width:{int(img_w)}px;height:{int(int(img_w)*1.48)}px;"
                        f"background:#f3f3f3;border:1px dashed #ccc;display:flex;"
                        f"align-items:center;justify-content:center;color:#888;'>"
                        f"–Ω–µ—Ç –ø–æ—Å—Ç–µ—Ä–∞</div>", unsafe_allow_html=True)

            with col_txt:
                st.markdown(f"**{title}**")
                if meta_line:
                    st.markdown(meta_line)

                people = []
                if (row.get("actors") or "").strip():
                    people.append(f"**–ê–∫—Ç—ë—Ä—ã:** {row['actors']}")
                if (row.get("directors") or "").strip():
                    people.append(f"**–†–µ–∂–∏—Å—Å—ë—Ä—ã:** {row['directors']}")
                if people:
                    st.markdown("  \n".join(people))

                if show_plot:
                    desc = (row.get("description") or "").strip()
                    if desc:
                        st.markdown(desc[:600] + ("‚Ä¶" if len(desc) > 600 else ""))

                url = str(row.get("page_url","")).strip()
                if _is_http_url(url):
                    st.markdown(f"[–û—Ç–∫—Ä—ã—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É]({url})")

            st.divider()

        st.caption("build: no-sidebar UI")

# ---------- main ----------
def main():
    ap = argparse.ArgumentParser(description="RAG over movie search (no-sidebar UI)")
    sub = ap.add_subparsers(dest="cmd")

    ap_a = sub.add_parser("answer", help="Ask a question and get a synthesized answer (CLI)")
    ap_a.add_argument("--index", required=True)
    ap_a.add_argument("--q", required=True)
    ap_a.add_argument("-k", type=int, default=10)
    ap_a.add_argument("--backend", default="openai")
    ap_a.add_argument("--model", default="gpt-4o-mini")
    ap_a.set_defaults(func=cmd_answer)

    ap_s = sub.add_parser("app", help="Run Streamlit UI (no sidebar)")
    ap_s.add_argument("--index", default="./index_hybrid")
    ap_s.set_defaults(func=cmd_app)

    args, _ = ap.parse_known_args()

    if args.cmd is None:
        args = argparse.Namespace(cmd="app", index="./index_hybrid")
        cmd_app(args); return
    args.func(args)

if __name__ == "__main__":
    main()
