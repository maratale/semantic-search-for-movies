#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RAG over hybrid movie search ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π UI + –≤–∫–ª–∞–¥–∫–∞ ¬´–û –º–æ–¥–µ–ª–∏¬ª.
- –í–∫–ª–∞–¥–∫–∞ ¬´–ü–æ–∏—Å–∫¬ª: –ø–æ–ª–µ –∑–∞–ø—Ä–æ—Å–∞, –æ—Ç–≤–µ—Ç LLM –∏ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ñ–∏–ª—å–º–æ–≤ —Å –ø–æ—Å—Ç–µ—Ä–∞–º–∏.
- –í–∫–ª–∞–¥–∫–∞ ¬´–û –º–æ–¥–µ–ª–∏¬ª: –æ–ø–∏—Å–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, TF-IDF, –≥–∏–±—Ä–∏–¥–Ω–æ–π —Å–º–µ—Å–∏, RAG –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏—è.

–ó–∞–ø—É—Å–∫: python -m streamlit run rag_movies.py -- app
"""

import os
import argparse
from typing import Optional
import pandas as pd
import requests
from urllib.parse import urlparse

# ====== –ù–ï–û–¢–û–ë–†–ê–ñ–ê–ï–ú–´–ï –ù–ê–°–¢–†–û–ô–ö–ò ============================================
INDEX_DIR   = "./index_hybrid"
TOP_K       = 10
LLM_MODEL   = "gpt-4o-mini"
IMG_WIDTH   = 200         # px
ALLOW_OGIMG = False       # True ‚Äî –ø—ã—Ç–∞—Ç—å—Å—è –±—Ä–∞—Ç—å og:image —Å page_url
SHOW_PLOT   = True        # –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ
# ============================================================================

# ---------- API key & client ----------
def _get_api_key() -> Optional[str]:
    key = os.getenv("OPENAI_API_KEY")
    if not key:
        try:
            import streamlit as st
            key = st.secrets.get("OPENAI_API_KEY", None) if hasattr(st, "secrets") else None
        except Exception:
            pass
    return key

def _make_client():
    key = _get_api_key()
    if not key:
        raise RuntimeError("OPENAI_API_KEY is not set (env or Streamlit secrets).")
    from openai import OpenAI
    return OpenAI(api_key=key)

# ---------- –ò–º–ø–æ—Ä—Ç —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ ----------
try:
    import semantic_search_movies as retr  # –æ–∂–∏–¥–∞–µ—Ç—Å—è run_query(out_dir, query, k)
except Exception:
    retr = None

# ---------- –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM ----------
def _shorten(s: str, n: int = 550) -> str:
    s = (s or "").strip()
    return s if len(s) <= n else s[:n].rsplit(" ", 1)[0] + "‚Ä¶"

def _as_year(x) -> str:
    s = str(x or "").strip()
    for ch in "[](){}":
        s = s.replace(ch, "")
    y = "".join(c for c in s if c.isdigit())
    return y[:4] if len(y) >= 4 else s

def _build_context(df: pd.DataFrame, k: int) -> str:
    blocks = []
    for _, row in df.head(k).iterrows():
        title = str(row.get("movie_title", "")).strip()
        year  = _as_year(row.get("release_date", ""))
        cats  = str(row.get("categories", "")).strip()
        actors = str(row.get("actors", "")).strip()
        directors = str(row.get("directors", "")).strip()
        desc = _shorten(str(row.get("description", "")))
        url  = str(row.get("page_url", "")).strip()
        b = [f"Title: {title}" + (f" ({year})" if year else "")]
        if cats:      b.append(f"Genres: {cats}")
        if directors: b.append(f"Directors: {directors}")
        if actors:    b.append(f"Cast: {actors}")
        if desc:      b.append(f"Plot: {desc}")
        if url.startswith("http"): b.append(f"URL: {url}")
        blocks.append("\n".join(b))
    return "\n\n---\n\n".join(blocks)

SYS_PROMPT = (
    "–¢—ã ‚Äî –∫–∏–Ω–æ–∫—Ä–∏—Ç–∏–∫ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞. –û—Ç–≤–µ—á–∞–π –ø–æ-—Ä—É—Å—Å–∫–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ.\n"
    "–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Å–ø–∏—Å–æ–∫ —Ñ–∏–ª—å–º–æ–≤), –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç–æ–≤.\n"
    "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:\n"
    "1) –ö–æ—Ä–æ—Ç–∫–æ –æ—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)\n"
    "2) –ü–æ–¥–±–æ—Ä–∫–∞ 5‚Äì10 —Ñ–∏–ª—å–º–æ–≤ —Å –ø—Ä–∏—á–∏–Ω–∞–º–∏ (–ø–æ 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ —Ñ–∏–ª—å–º)\n"
    "3) –ï—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã/–ø–æ–¥–±–æ—Ä–∫–∏\n"
    "–í—Å–µ–≥–¥–∞ —É–∫–∞–∑—ã–≤–∞–π –≥–æ–¥, –∂–∞–Ω—Ä—ã, –º–æ–∂–Ω–æ –∞–∫—Ç—ë—Ä–æ–≤/—Ä–µ–∂–∏—Å—Å—ë—Ä–æ–≤; –¥–æ–±–∞–≤–ª—è–π —Å—Å—ã–ª–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å.\n"
)

USER_PROMPT_TMPL = (
    "–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n{query}\n\n"
    "–ö–æ–Ω—Ç–µ–∫—Å—Ç (–∫–∞–Ω–¥–∏–¥–∞—Ç—ã —Ñ–∏–ª—å–º–æ–≤):\n{context}\n\n"
    "–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤—ã–±—Ä–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ–∏–ª—å–º—ã, "
    "–æ–±—ä—è—Å–Ω–∏—Ç—å –≤—ã–±–æ—Ä –∏ —Å–≤—è–∑–∞—Ç—å –∏—Ö —Å –∑–∞–ø—Ä–æ—Å–æ–º. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –ø–æ–∫—Ä—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å, "
    "—á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ —ç—Ç–æ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –±–ª–∏–∂–∞–π—à–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n"
)

# ---------- LLM ----------
def call_openai(prompt: str, system: str = SYS_PROMPT, model: str = LLM_MODEL) -> str:
    try:
        client = _make_client()
        r = client.chat.completions.create(
            model=model,
            messages=[{"role": "system", "content": system},
                      {"role": "user",   "content": prompt}],
            temperature=0.4,
            max_tokens=900,
        )
        return r.choices[0].message.content.strip()
    except Exception as e_new:
        try:
            import openai
            key = _get_api_key()
            if not key:
                return f"[LLM disabled] {e_new}\n\n" + prompt
            openai.api_key = key
            r = openai.ChatCompletion.create(
                model=model,
                messages=[{"role": "system", "content": system},
                          {"role": "user",   "content": prompt}],
                temperature=0.4,
                max_tokens=900,
            )
            return r["choices"][0]["message"]["content"].strip()
        except Exception as e_old:
            return f"[OpenAI error] {e_old}\n\n" + prompt

# ---------- –†–µ—Ç—Ä–∏–≤–µ—Ä-–æ–±—ë—Ä—Ç–∫–∞ ----------
def retrieve(index_dir: str, query: str, k: int = TOP_K) -> pd.DataFrame:
    if retr and hasattr(retr, "run_query"):
        return retr.run_query(index_dir, query, k=k)
    meta_path = os.path.join(index_dir, "meta.parquet")
    if not os.path.exists(meta_path):
        raise FileNotFoundError(f"No meta.parquet in {index_dir}; build your index first.")
    df = pd.read_parquet(meta_path)
    q = query.lower()
    mask = (
        df.get("movie_title", pd.Series(dtype=str)).str.lower().str.contains(q, na=False) |
        df.get("directors",   pd.Series(dtype=str)).str.lower().str.contains(q, na=False) |
        df.get("actors",      pd.Series(dtype=str)).str.lower().str.contains(q, na=False) |
        df.get("description", pd.Series(dtype=str)).str.lower().str.contains(q, na=False)
    )
    out = df[mask].copy()
    if out.empty:
        out = df.sample(min(k, len(df)), random_state=42).copy()
    out.insert(0, "final_score", 0.0)
    return out.head(k)

def rag_answer(index_dir: str, query: str, k: int = TOP_K):
    hits = retrieve(index_dir, query, k=max(k, 12))
    ctx  = _build_context(hits, k=max(k, 12))
    prompt = USER_PROMPT_TMPL.format(query=query, context=ctx)
    return call_openai(prompt, model=LLM_MODEL), hits

# ---------- –ü–æ—Å—Ç–µ—Ä—ã ----------
try:
    from bs4 import BeautifulSoup
    HAS_BS4 = True
except Exception:
    HAS_BS4 = False

def _is_http_url(s: str) -> bool:
    try:
        u = urlparse(str(s).strip())
        return u.scheme in ("http", "https") and bool(u.netloc)
    except Exception:
        return False

def _clean_url(s: str) -> str:
    return str(s or "").strip()

def _safe_get(url: str, timeout: float = 5.0) -> Optional[requests.Response]:
    try:
        headers = {"User-Agent": "Mozilla/5.0 (compatible; RAGMoviesBot/1.0)"}
        r = requests.get(url, headers=headers, timeout=timeout)
        if r.status_code == 200 and r.content:
            return r
    except Exception:
        pass
    return None

def _extract_og_image(html: str) -> Optional[str]:
    if not HAS_BS4:
        return None
    try:
        soup = BeautifulSoup(html, "html.parser")
        for prop in ("og:image", "twitter:image", "og:image:url"):
            tag = soup.find("meta", attrs={"property": prop}) or soup.find("meta", attrs={"name": prop})
            if tag:
                content = tag.get("content") or tag.get("value")
                if content and _is_http_url(content):
                    return content
    except Exception:
        pass
    return None

# ---------- CLI ----------
def cmd_answer(args):
    ans, hits = rag_answer(INDEX_DIR, args.q, k=args.k)
    print("\n=== ANSWER ===\n")
    print(ans)
    print("\n=== SOURCES ===\n")
    cols = [c for c in ["movie_title","release_date","categories","actors","directors","page_url"] if c in hits.columns]
    print(hits.head(args.k)[cols].to_string(index=False, max_colwidth=120))

# ---------- Streamlit (–¥–≤–µ –≤–∫–ª–∞–¥–∫–∏, –±–µ–∑ —Å–∞–π–¥–±–∞—Ä–∞) ----------
def cmd_app(_args):
    import streamlit as st
    st.set_page_config(page_title="RAG over Movies", layout="wide")
    st.title("üé¨ –ü–æ–∏—Å–∫ —Ñ–∏–ª—å–º–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")

    tabs = st.tabs(["–ü–æ–∏—Å–∫", "–û –º–æ–¥–µ–ª–∏"])

    # --- –≤–∫–ª–∞–¥–∫–∞ ¬´–ü–æ–∏—Å–∫¬ª ---
    with tabs[0]:
        if not _get_api_key():
            st.warning("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞.")

        q = st.text_input("–ü–æ–∏—Å–∫")
        go = st.button("–ù–∞–π—Ç–∏")

        @st.cache_data(show_spinner=False)
        def cached_poster_from_page(url: str) -> Optional[str]:
            resp = _safe_get(url)
            if resp is None:
                return None
            og = _extract_og_image(resp.text)
            return og if (og and _is_http_url(og)) else None

        if go and q.strip():
            with st.spinner("–ò—â–µ–º –≤–∞—à —Ñ–∏–ª—å–º"):
                ans, hits = rag_answer(INDEX_DIR, q, k=TOP_K)

            st.markdown("## –û—Ç–≤–µ—Ç")
            st.write(ans)

            st.markdown("## –ü–æ–¥–±–æ—Ä–∫–∞ —Ñ–∏–ª—å–º–æ–≤")
            for _, row in hits.iterrows():
                title = str(row.get("movie_title","(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)")).strip() or "(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)"
                meta_line = " | ".join(filter(None, [
                    str(row.get("categories","")).strip(),
                    str(row.get("release_date","")).strip(),
                ]))

                # –ø–æ—Å—Ç–µ—Ä
                poster = None
                for key in ("poster_url","image_url","poster","thumbnail"):
                    val = _clean_url(row.get(key, ""))
                    if _is_http_url(val):
                        poster = val
                        break
                if poster is None and ALLOW_OGIMG:
                    page_url = _clean_url(row.get("page_url",""))
                    if _is_http_url(page_url):
                        poster = cached_poster_from_page(page_url)

                box = st.container()
                col_img, col_txt = box.columns([1,3], vertical_alignment="center")

                with col_img:
                    if poster:
                        st.image(poster, width=IMG_WIDTH)
                    else:
                        st.markdown(
                            f"<div style='width:{IMG_WIDTH}px;height:{int(IMG_WIDTH*1.48)}px;"
                            f"background:#f3f3f3;border:1px dashed #ccc;display:flex;"
                            f"align-items:center;justify-content:center;color:#888;'>–Ω–µ—Ç –ø–æ—Å—Ç–µ—Ä–∞</div>",
                            unsafe_allow_html=True)

                with col_txt:
                    st.markdown(f"**{title}**")
                    if meta_line:
                        st.markdown(meta_line)

                    people = []
                    if (row.get("actors") or "").strip():
                        people.append(f"**–ê–∫—Ç—ë—Ä—ã:** {row['actors']}")
                    if (row.get("directors") or "").strip():
                        people.append(f"**–†–µ–∂–∏—Å—Å—ë—Ä—ã:** {row['directors']}")
                    if people:
                        st.markdown("  \n".join(people))

                    if SHOW_PLOT:
                        desc = (row.get("description") or "").strip()
                        if desc:
                            st.markdown(desc[:600] + ("‚Ä¶" if len(desc) > 600 else ""))

                    url = str(row.get("page_url","")).strip()
                    if _is_http_url(url):
                        st.markdown(f"[–û—Ç–∫—Ä—ã—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É]({url})")

                st.divider()

    # --- –≤–∫–ª–∞–¥–∫–∞ ¬´–û –º–æ–¥–µ–ª–∏¬ª ---
    with tabs[1]:
        st.markdown("## –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        st.markdown(
            """
**–°—Ç–µ–∫:**
- –≠–º–±–µ–¥–¥–∏–Ω–≥–∏: `intfloat/multilingual-e5-base` (768-D). –ü—Ä–µ—Ñ–∏–∫—Å—ã: `passage:` –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, `query:` –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤; L2-–Ω–æ—Ä–º–∞ ‚Üí cosine = inner product.
- –ü–æ–∏—Å–∫: –ø–µ—Ä–≤–∏—á–Ω—ã–π ANN —á–µ—Ä–µ–∑ FAISS (–∏–ª–∏ sklearn fallback), —à–∏—Ä–æ–∫–∏–π top-*k0*.
- TF-IDF: —Ç—Ä–∏ –∫–∞–Ω–∞–ª–∞ ‚Äî `title`, `text` (–Ω–∞–∑–≤–∞–Ω–∏–µ|–æ–ø–∏—Å–∞–Ω–∏–µ|–∂–∞–Ω—Ä—ã|–ª—é–¥–∏|–¥–∞—Ç–∞), `people` (actors+directors).
- –≠–≤—Ä–∏—Å—Ç–∏–∫–∏: `title_boost` (—Ç–æ—á–Ω–æ–µ/–ø—Ä–µ—Ñ–∏–∫—Å–Ω–æ–µ/overlap/fuzzy), `people_direct_hit`.
- –ì–∏–±—Ä–∏–¥–Ω–∞—è —Å–º–µ—Å—å —Å–∏–≥–Ω–∞–ª–æ–≤ (min‚Äìmax –ø–æ k0):
  - **–ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (–∏–º—è/—Ñ–∞–º–∏–ª–∏—è):** `0.35*sbert + 0.20*title + 0.05*text + 0.25*people + 0.15*direct`
  - **–æ–±—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã:** `0.45*sbert + 0.25*title + 0.10*text + 0.10*people + 0.10*title_boost`
- RAG: —Ç–æ–ø-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã ‚Üí –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç ‚Üí GPT-4o-mini —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è.

**–ü–∞–π–ø–ª–∞–π–Ω:**
1. CSV ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–µ–π ‚Üí `search_text`, `people_text`.
2. E5(`passage:`) ‚Üí `embeddings.npy`; TF-IDF –º–∞—Ç—Ä–∏—Ü—ã –ø–æ –∫–∞–Ω–∞–ª–∞–º.
3. –ó–∞–ø—Ä–æ—Å ‚Üí alias-—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ ‚Üí E5(`query:`) ‚Üí ANN top-k0.
4. –ù–∞ k0 —Å—á–∏—Ç–∞–µ–º TF-IDF –∏ –±—É—Å—Ç—ã ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è ‚Üí —Å–º–µ—Å—å ‚Üí —Ñ–∏–Ω–∞–ª—å–Ω—ã–π top-k.
5. RAG —Å–æ–±–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç (title/year/genres/cast/plot/url) –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç.

**–ê–ª–∏–∞—Å—ã:** —Ç—Ä–∏–≥–≥–µ—Ä—ã –Ω–∞ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ñ—Ä–∞–Ω—à–∏–∑—ã/–ø–µ—Ä—Å–æ–Ω—ã (HP/LOTR/Marvel/–¢–∞—Ä–∞–Ω—Ç–∏–Ω–æ); —Ä–∞—Å—à–∏—Ä—è–µ–º–æ.

**–û–±–æ–≥–∞—â–µ–Ω–∏–µ:**
- –û—Ñ—Ñ–ª–∞–π–Ω-—Å–∫—Ä–∏–ø—Ç —á–µ—Ä–µ–∑ GPT-4o-mini –∏–∑–≤–ª–µ–∫–∞–µ—Ç `themes`, `tropes`, `mood`, `setting`, `keywords_ru/en`, `alt_titles`, `entities` (—Å—Ç—Ä–æ–≥–∏–π JSON).
- –≠—Ç–∏ –ø–æ–ª—è –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ `search_text`/`topics_text` + –Ω–æ–≤—ã–π TF-IDF –∫–∞–Ω–∞–ª; –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ‚Äî —Å–ª–æ–∂–∏—Ç—å `E5(base)+E5(enriched)` –∏ –ø–µ—Ä–µ–Ω–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å.

**–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**
- –î–æ 100‚Äì300k —Ñ–∏–ª—å–º–æ–≤ ‚Äî FAISS Flat –Ω–∞ CPU.
"""
)
# ---------- main ----------
def main():
    ap = argparse.ArgumentParser(description="RAG over movie search (two tabs)")
    sub = ap.add_subparsers(dest="cmd")

    ap_a = sub.add_parser("answer", help="Ask via CLI and print answer")
    ap_a.add_argument("--q", required=True)
    ap_a.add_argument("-k", type=int, default=TOP_K)
    ap_a.set_defaults(func=cmd_answer)

    ap_s = sub.add_parser("app", help="Run Streamlit UI")
    ap_s.set_defaults(func=cmd_app)

    args, _ = ap.parse_known_args()
    if args.cmd is None:
        args = argparse.Namespace(cmd="app")
        cmd_app(args)
        return
    args.func(args)

if __name__ == "__main__":
    main()
