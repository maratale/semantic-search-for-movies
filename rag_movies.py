#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RAG over hybrid movie search, with poster cards in Streamlit.
- –ë–µ—Ä—ë—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ semantic_search_movies.run_query (–≤–∞—à –≥–∏–±—Ä–∏–¥–Ω—ã–π –∏–Ω–¥–µ–∫—Å).
- –°–æ–±–∏—Ä–∞–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (title, year, genres, cast, plot, url).
- –í—ã–∑—ã–≤–∞–µ—Ç LLM –¥–ª—è —Å–≤—è–∑–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: —Ä–µ–∑—é–º–µ, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, —Å–≤—è–∑–∏.
- –í Streamlit —Ä–µ–Ω–¥–µ—Ä–∏—Ç –∫–∞—Ä—Ç–æ—á–∫–∏ —Ñ–∏–ª—å–º–æ–≤ —Å –ø–æ—Å—Ç–µ—Ä–æ–º (–∏–∑ poster_url –∏–ª–∏ og:image –ø–æ page_url).

–ó–∞–ø—É—Å–∫:
  # CLI
  python rag_movies.py answer --index ./index_hybrid --q "—Ä–æ–º–∫–æ–º –≤ –±–æ–ª—å—à–æ–º –≥–æ—Ä–æ–¥–µ" --k 8

  # Streamlit
  python -m streamlit run rag_movies.py -- app --index ./index_hybrid

–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
  OPENAI_API_KEY ‚Äî –¥–ª—è OpenAI backend (–≤ Streamlit Cloud –ø–æ–ª–æ–∂–∏—Ç–µ –≤ Secrets).
"""

print("RAG build stamp: 2025-10-03T12:00Z")

import os, sys, argparse
import pandas as pd
from typing import Optional

# ---------- API key & client ----------
def _get_api_key() -> str | None:
    key = os.getenv("OPENAI_API_KEY")
    if not key:
        # –í Streamlit Cloud –∫–ª—é—á –º–æ–∂–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—å –≤ Secrets
        try:
            import streamlit as st
            key = st.secrets.get("OPENAI_API_KEY", None) if hasattr(st, "secrets") else None
        except Exception:
            pass
    return key

def _make_client():
    key = _get_api_key()
    if not key:
        raise RuntimeError("OPENAI_API_KEY is not set (env or Streamlit secrets).")
    # –ò–º–ø–æ—Ä—Ç –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏, —á—Ç–æ–±—ã –º–æ–¥—É–ª—å –≥—Ä—É–∑–∏–ª—Å—è –¥–∞–∂–µ –±–µ–∑ openai
    from openai import OpenAI
    return OpenAI(api_key=key)

# ---------- –ò–º–ø–æ—Ä—Ç —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ ----------
try:
    import semantic_search_movies as retr  # –æ–∂–∏–¥–∞–µ—Ç—Å—è —Ñ—É–Ω–∫—Ü–∏—è run_query(out_dir, query, k)
except Exception:
    retr = None

# ---------- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ ----------
def _shorten(s: str, n: int = 550) -> str:
    s = (s or "").strip()
    return s if len(s) <= n else s[:n].rsplit(" ", 1)[0] + "‚Ä¶"

def _as_year(x) -> str:
    s = str(x or "").strip()
    for ch in "[](){}":
        s = s.replace(ch, "")
    y = "".join(c for c in s if c.isdigit())
    return y[:4] if len(y) >= 4 else s

def _build_context(df: pd.DataFrame, k: int) -> str:
    blocks = []
    for _, row in df.head(k).iterrows():
        title = str(row.get("movie_title", "")).strip()
        year  = _as_year(row.get("release_date", ""))
        cats  = str(row.get("categories", "")).strip()
        actors = str(row.get("actors", "")).strip()
        directors = str(row.get("directors", "")).strip()
        desc = _shorten(str(row.get("description", "")))
        url  = str(row.get("page_url", "")).strip()

        b = []
        b.append(f"Title: {title}" + (f" ({year})" if year else ""))
        if cats:      b.append(f"Genres: {cats}")
        if directors: b.append(f"Directors: {directors}")
        if actors:    b.append(f"Cast: {actors}")
        if desc:      b.append(f"Plot: {desc}")
        if url.startswith("http"): b.append(f"URL: {url}")
        blocks.append("\n".join(b))
    return "\n\n---\n\n".join(blocks)

SYS_PROMPT = (
    "–¢—ã ‚Äî –∫–∏–Ω–æ–∫—Ä–∏—Ç–∏–∫ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞. –û—Ç–≤–µ—á–∞–π –ø–æ-—Ä—É—Å—Å–∫–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ.\n"
    "–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Å–ø–∏—Å–æ–∫ —Ñ–∏–ª—å–º–æ–≤), –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç–æ–≤.\n"
    "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:\n"
    "1) –ö–æ—Ä–æ—Ç–∫–æ –æ—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)\n"
    "2) –ü–æ–¥–±–æ—Ä–∫–∞ 5‚Äì10 —Ñ–∏–ª—å–º–æ–≤ —Å –ø—Ä–∏—á–∏–Ω–∞–º–∏ (–ø–æ 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ —Ñ–∏–ª—å–º)\n"
    "3) –ï—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã/–ø–æ–¥–±–æ—Ä–∫–∏\n"
    "–í—Å–µ–≥–¥–∞ —É–∫–∞–∑—ã–≤–∞–π –≥–æ–¥, –∂–∞–Ω—Ä—ã, –º–æ–∂–Ω–æ –∞–∫—Ç—ë—Ä–æ–≤/—Ä–µ–∂–∏—Å—Å—ë—Ä–æ–≤; –¥–æ–±–∞–≤–ª—è–π —Å—Å—ã–ª–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å.\n"
)

USER_PROMPT_TMPL = """–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
{query}

–ö–æ–Ω—Ç–µ–∫—Å—Ç (–∫–∞–Ω–¥–∏–¥–∞—Ç—ã —Ñ–∏–ª—å–º–æ–≤):
{context}

–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤—ã–±—Ä–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ–∏–ª—å–º—ã, –æ–±—ä—è—Å–Ω–∏—Ç—å –≤—ã–±–æ—Ä –∏ —Å–≤—è–∑–∞—Ç—å –∏—Ö —Å –∑–∞–ø—Ä–æ—Å–æ–º.
–ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –ø–æ–∫—Ä—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ —ç—Ç–æ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –±–ª–∏–∂–∞–π—à–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
"""

# ---------- –í—ã–∑–æ–≤ LLM ----------
def call_openai(prompt: str, system: str = SYS_PROMPT, model: str = "gpt-4o-mini") -> str:
    # –æ—Å–Ω–æ–≤–Ω–æ–π –ø—É—Ç—å: –Ω–æ–≤—ã–π SDK (openai>=1.x)
    try:
        client = _make_client()
        r = client.chat.completions.create(
            model=model,
            messages=[{"role": "system", "content": system},
                      {"role": "user", "content": prompt}],
            temperature=0.4,
            max_tokens=900,
        )
        return r.choices[0].message.content.strip()
    except Exception as e_new:
        # —Ñ–æ–ª–±—ç–∫: —Å—Ç–∞—Ä—ã–π SDK (openai 0.x), –µ—Å–ª–∏ –æ–Ω –≤–Ω–µ–∑–∞–ø–Ω–æ –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏
        try:
            import openai
            key = _get_api_key()
            if not key:
                return f"[LLM disabled] {e_new}\n\n" + prompt
            openai.api_key = key
            r = openai.ChatCompletion.create(
                model=model,
                messages=[{"role": "system", "content": system},
                          {"role": "user", "content": prompt}],
                temperature=0.4,
                max_tokens=900,
            )
            return r["choices"][0]["message"]["content"].strip()
        except Exception as e_old:
            return f"[OpenAI error] {e_old}\n\n" + prompt

# ---------- –†–µ—Ç—Ä–∏–≤–µ—Ä-–æ–±—ë—Ä—Ç–∫–∞ ----------
def retrieve(index_dir: str, query: str, k: int = 12) -> pd.DataFrame:
    if retr and hasattr(retr, "run_query"):
        # –æ–∂–∏–¥–∞–µ—Ç—Å—è —Å–∏–≥–Ω–∞—Ç—É—Ä–∞ run_query(out_dir, query, k=...)
        return retr.run_query(index_dir, query, k=k)
    # fallback: –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ, –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –Ω–µ —Å–æ–±—Ä–∞–Ω/–Ω–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    meta_path = os.path.join(index_dir, "meta.parquet")
    if not os.path.exists(meta_path):
        raise FileNotFoundError(f"No meta.parquet in {index_dir}; build your index first.")
    df = pd.read_parquet(meta_path)
    q = query.lower()
    mask = (
        df.get("movie_title", pd.Series(dtype=str)).str.lower().str.contains(q, na=False) |
        df.get("directors", pd.Series(dtype=str)).str.lower().str.contains(q, na=False) |
        df.get("actors", pd.Series(dtype=str)).str.lower().str.contains(q, na=False) |
        df.get("description", pd.Series(dtype=str)).str.lower().str.contains(q, na=False)
    )
    out = df[mask].copy()
    if out.empty:
        out = df.sample(min(k, len(df)), random_state=42).copy()
    out.insert(0, "final_score", 0.0)
    return out.head(k)

# ---------- RAG ----------
def rag_answer(index_dir: str, query: str, k: int = 10,
               llm_backend: str = "openai", llm_model: str = "gpt-4o-mini") -> tuple[str, pd.DataFrame]:
    hits = retrieve(index_dir, query, k=max(k, 12))
    ctx = _build_context(hits, k=max(k, 12))
    prompt = USER_PROMPT_TMPL.format(query=query, context=ctx)
    if llm_backend == "openai":
        answer = call_openai(prompt, model=llm_model)
    else:
        answer = "[No LLM backend configured]\n\n" + prompt
    return answer, hits

# ---------- –ü–æ—Å—Ç–µ—Ä—ã: —É—Ç–∏–ª–∏—Ç—ã ----------
import requests
from urllib.parse import urlparse
try:
    from bs4 import BeautifulSoup
    HAS_BS4 = True
except Exception:
    HAS_BS4 = False

def _is_http_url(s: str) -> bool:
    try:
        u = urlparse(str(s).strip())
        return u.scheme in ("http", "https") and bool(u.netloc)
    except Exception:
        return False

def _clean_url(s: str) -> str:
    return str(s or "").strip()

def _safe_get(url: str, timeout: float = 5.0) -> Optional[requests.Response]:
    try:
        headers = {"User-Agent": "Mozilla/5.0 (compatible; RAGMoviesBot/1.0)"}
        r = requests.get(url, headers=headers, timeout=timeout)
        if r.status_code == 200 and r.content:
            return r
    except Exception:
        pass
    return None

def _extract_og_image(html: str) -> Optional[str]:
    if not HAS_BS4:
        return None
    try:
        soup = BeautifulSoup(html, "html.parser")
        for prop in ("og:image", "twitter:image", "og:image:url"):
            tag = soup.find("meta", attrs={"property": prop}) or soup.find("meta", attrs={"name": prop})
            if tag:
                content = tag.get("content") or tag.get("value")
                if content and _is_http_url(content):
                    return content
    except Exception:
        pass
    return None

# ---------- CLI ----------
def cmd_answer(args):
    ans, hits = rag_answer(args.index, args.q, k=args.k, llm_backend=args.backend, llm_model=args.model)
    print("\n=== ANSWER ===\n")
    print(ans)
    print("\n=== SOURCES ===\n")
    cols = [c for c in ["movie_title","release_date","categories","actors","directors","page_url"] if c in hits.columns]
    print(hits.head(args.k)[cols].to_string(index=False, max_colwidth=120))

# ---------- Streamlit UI ----------
def cmd_app(args):
    import streamlit as st
    st.set_page_config(page_title="RAG over Movies", layout="wide")
    st.title("üß† RAG –ø–æ —Ñ–∏–ª—å–º–∞–º (–ø–æ–≤–µ—Ä—Ö –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞)")

    index_dir = st.sidebar.text_input("–ü–∞–ø–∫–∞ –∏–Ω–¥–µ–∫—Å–∞", args.index or "./index_hybrid")
    k = st.sidebar.slider("Top-K –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", 5, 20, 10)
    llm_model = st.sidebar.selectbox("LLM –º–æ–¥–µ–ª—å", ["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini", "gpt-4.1"], index=0)

    st.sidebar.markdown("---")
    st.sidebar.markdown("**–ü–æ—Å—Ç–µ—Ä—ã**")
    img_w = st.sidebar.slider("–®–∏—Ä–∏–Ω–∞ –ø–æ—Å—Ç–µ—Ä–∞, px", 120, 360, 200, step=10)
    allow_fetch = st.sidebar.checkbox("–ü—Ä–æ–±–æ–≤–∞—Ç—å og:image –∏–∑ page_url", value=False,
                                      help="–ï—Å–ª–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç poster_url, –ø–æ–ø—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
    show_plot = st.sidebar.checkbox("–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ", value=True)

    has_key = bool(_get_api_key())
    if not has_key:
        st.warning("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è, –Ω–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞.\n"
                   "–í Streamlit Cloud –¥–æ–±–∞–≤—å—Ç–µ —Å–µ–∫—Ä–µ—Ç OPENAI_API_KEY –≤ Settings ‚Üí Secrets.")

    @st.cache_data(show_spinner=False)
    def cached_poster_from_page(url: str) -> Optional[str]:
        resp = _safe_get(url)
        if resp is None:
            return None
        og = _extract_og_image(resp.text)
        return og if (og and _is_http_url(og)) else None

    q = st.text_input("–í–∞—à –∑–∞–ø—Ä–æ—Å", "—Ä–æ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –∫–æ–º–µ–¥–∏—è –≤ –±–æ–ª—å—à–æ–º –≥–æ—Ä–æ–¥–µ")
    if st.button("–°–ø—Ä–æ—Å–∏—Ç—å", disabled=not has_key) and q.strip():
        with st.spinner("–ì–æ—Ç–æ–≤–∏–º –æ—Ç–≤–µ—Ç‚Ä¶"):
            ans, hits = rag_answer(index_dir, q, k=k, llm_backend="openai", llm_model=llm_model)
        st.markdown("### –û—Ç–≤–µ—Ç")
        st.write(ans)

        st.markdown("### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (—Ç–∞–±–ª–∏—Ü–∞)")
        cols = [c for c in ["movie_title","release_date","categories","actors","directors","description","page_url","poster_url"] if c in hits.columns]
        st.dataframe(hits[cols], use_container_width=True)

        st.markdown("### –ö–∞—Ä—Ç–æ—á–∫–∏ —Ñ–∏–ª—å–º–æ–≤")
        for _, row in hits.iterrows():
            title = str(row.get("movie_title","(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)")).strip() or "(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)"
            meta_line = " | ".join(filter(None, [
                str(row.get("categories","")) .strip(),
                str(row.get("release_date","")) .strip(),
            ]))

            # –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ—Å—Ç–µ—Ä
            poster = None
            for key in ("poster_url","image_url","poster","thumbnail"):
                val = _clean_url(row.get(key, ""))
                if _is_http_url(val):
                    poster = val
                    break
            if poster is None and allow_fetch:
                page_url = _clean_url(row.get("page_url",""))
                if _is_http_url(page_url):
                    poster = cached_poster_from_page(page_url)

            box = st.container()
            col_img, col_txt = box.columns([1,3], vertical_alignment="center")

            with col_img:
                if poster:
                    st.image(poster, width=img_w)
                else:
                    st.markdown(
                        f"<div style='width:{img_w}px;height:{int(img_w*1.48)}px;background:#f3f3f3;"
                        f"border:1px dashed #ccc;display:flex;align-items:center;justify-content:center;color:#888;'>"
                        f"–Ω–µ—Ç –ø–æ—Å—Ç–µ—Ä–∞</div>", unsafe_allow_html=True)

            with col_txt:
                st.markdown(f"**{title}**")
                if meta_line:
                    st.markdown(meta_line)

                people = []
                if (row.get("actors") or "").strip():
                    people.append(f"**–ê–∫—Ç—ë—Ä—ã:** {row['actors']}")
                if (row.get("directors") or "").strip():
                    people.append(f"**–†–µ–∂–∏—Å—Å—ë—Ä—ã:** {row['directors']}")
                if people:
                    st.markdown("  \n".join(people))

                if show_plot:
                    desc = (row.get("description") or "").strip()
                    if desc:
                        st.markdown(desc[:600] + ("‚Ä¶" if len(desc) > 600 else ""))

                url = str(row.get("page_url","")) .strip()
                if _is_http_url(url):
                    st.markdown(f"[–û—Ç–∫—Ä—ã—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É]({url})")

            st.divider()

    st.caption("build: 2025-10-03T12:00Z")

# ---------- main ----------
def main():
    ap = argparse.ArgumentParser(description="RAG over movie search")
    sub = ap.add_subparsers(dest="cmd")

    ap_a = sub.add_parser("answer", help="Ask a question and get a synthesized answer")
    ap_a.add_argument("--index", required=True)
    ap_a.add_argument("--q", required=True)
    ap_a.add_argument("-k", type=int, default=10)
    ap_a.add_argument("--backend", default="openai")
    ap_a.add_argument("--model", default="gpt-4o-mini")
    ap_a.set_defaults(func=cmd_answer)

    ap_s = sub.add_parser("app", help="Run Streamlit UI")
    ap_s.add_argument("--index", default="./index_hybrid")
    ap_s.set_defaults(func=cmd_app)

    args, _ = ap.parse_known_args()

    # –ï—Å–ª–∏ –∫–æ–º–∞–Ω–¥ –Ω–µ—Ç ‚Äî –∑–∞–ø—É—Å–∫–∞–µ–º UI —Å –¥–µ—Ñ–æ–ª—Ç–∞–º–∏.
    if args.cmd is None:
        args = argparse.Namespace(cmd="app", index="./index_hybrid")
        cmd_app(args)
        return

    args.func(args)

if __name__ == "__main__":
    main()
